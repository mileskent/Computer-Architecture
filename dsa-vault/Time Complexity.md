Describe how the runtime of an algorithm changes as a [[Big O]] function of the size of its input.
For example, the [[Big O]] time complexity of [[Bubble Sort]] is $O(n^2)$. Furthermore, there is Big Omega, which indicates the best case scenario specifically, whereas Big O usually implies worst case time complexity. In the case of bubble sort it is $\Omega(n)$, due to the trivial case of already sorted data. In other words, Big O is the asymptotic upper bound and the big Omega is the asymptotic lower bound of the algorithm. 

### See also 
[[Auxiliary Space Complexity]]