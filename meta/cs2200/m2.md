# Pipelining 
## Stages & Buffers
What are the 5 stages of the pipeline? What does each do?
> [!success]- Solution
Stages
> 1. IF (Instruction Fetch)
> 2. ID/RR (Instruction Decode / Reset Register)
> 3. EX (Execute)
> 4. MEM (Memory Access)
> 5. WB (Write Back)
> 
> Responsibilities
> 1. IF - fetch instruction in IR and increment PC
> 2. ID/RR - decode and read register contents
> 3. EX - performan arithmetic/logic if needed, address computation if needed
> 4. MEM - fetch/store memory operand if needed
> 5. WB - write to register if needed

Summarize the function of each of the pipeline buffers between the stages, i.e. buffer, who's output is it, contents.
> [!success]- Solution
> The opcode is passed through ALL buffers because it encodes what the appropriate datapath actions are for next stage
> It is stored at the beginning of ALL buffers
> ![[Pasted image 20251007165740.png|400]]
>
> | Buffer | Who's Output? | Contents                                                                                                                              |
> | ------ | ------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
> | FBUF   | IF            | Essentially contains the IR                                                                                                           |
> | DBUF   | ID/RR         | Decoded IR and values read from<br>register file                                                                                      |
> | EBUF   | EX            | Primarily contains result of ALU<br>operation plus other parts of the<br>instruction depending on the<br>instruction specifics        |
> | MBUF   | MEM           | Same as EBUF if instruction is not<br>LW or SW; If instruction is LW,<br>then buffer contains the contents<br>of memory location read |

Trace the flow of data through the pipeline buffers during an ADD
> [!success]- Solution
> 
> ADD Pseudocode: RX = RY + RZ
> ADD Microcode:
> 1. A = RY
> 2. B = RZ
> 3. RX = ALU_ADD
> 
> * IF stage (cycle 1):
> 	* FBUF = I-MEM\[PC\]
> 		* The instruction at memory address given by PC is fetched and placed in FBUF (which is essentially the IR)
> 	* PC++
> * ID/RR stage (cycle 2):
> 	* DBUF\[A\] = DPRF\[ FBUF\[Ry\] \]
> 	* DBUF\[B\] = DPRF\[ FBUF\[Rz\] \]
> 	* DBUF\[OPCODE\] = FBUF\[OPCODE\]
> 	* DBUF\[Rx\] = FBUF\[Rx\]
> * EX stage (cycle 3)
> 	* EBUF\[ALU_RESULT\] = DBUF\[A\] + DBUF\[B\]
> 	* EBUF\[OPCODE\] = DBUF\[OPCODE\]
> 	* EBUF\[Rx\] = DBUF\[Rx\]
> * MEM stage (cycle 4)
> 	* MBUF = EBUF
> 		* (MEM doesn't contribute to ADD, so we just copy everything over)
> * WB stage (cycle 5)
> 	* DPRF\[MBUF\[Rx\]\] = MBUF\[ALU_RESULT\]

## Structual Hazards
What is a structual hazard?
> [!success]- Solution
Structual hazards are caused by hardware limitations.
For example, if BEQ branches, we have to use the ALU twice! If we only have one ALU in the datapath for EX, then all the insructions behind the BEQ in the pipeline have to wait for it, as it cycles twice in EX.

## Data Hazards
What is a data hazard?
> [!success]- Solution
> When pipelining destroys the serial semantics of a program. 
> 

 What are the 3 kinds of data hazards?
> [!success]- Solution
> The 3 kinds of data hazards are:
> 1. Read after Write (RAW)
> 2. Write after Read (WAR)
> 3. Write after Write (WAW)
> 
> RAW Example:
> 4. $R_{\color{red}\mathbf{1}} =R_{2}+R_{3}$
> 5. $R_{4} =R_{\color{red}\mathbf{1}}+R_{5}$
> Inst 1 writes the new value of $R_{1}$ at stage 5 (WB). However, Inst 2 first needs $R_{1}$ in stage 2 (ID/RR), before Inst 1 has even gotten to stage 5. In order to fix this, Inst 2 must stall in the pipeline for 3 cycles, waiting for Inst 1 to finish stage 5, before continuing.
> 
> WAR Example:
> 6. $R_{4} =R_{\color{red}\mathbf{1}}+R_{5}$
> 7. $R_{\color{red}\mathbf{1}} =R_{2}+R_{3}$
> A WAR hazard doesn't cause an issue in our pipeline because by the time Inst 2 starts, Inst 1 has already read its registers into DBUF.
> 
> WAW Example:
> 8. $R_{\color{red}\mathbf{1}} =R_{2}+R_{3}$
> 9. $R_{\color{red}\mathbf{1}} =R_{4}+R_{5}$
> A WAW hazard doesn't cause an issue in our pipeline.

## Control Hazards
What is a control hazard?
> [!success]- Solution
> Changes to the control flow of a process, e.g. branching.
>
> "Branches cause disruption to the normal flow of control and are detrimental to pipelined processor performance"

## Hazard Handling
Why are hazards bad?
> [!success]- Solution
Hazards are bad because they can result in pipeline stalling, which approaches serialization as it get worse; the closer we get to serialization the closer we are to a non-pipelined processor, and the slower we are.

How many bubbles $B$ are associated with a given RAW hazard, with $n$ being the number of unrelated instructions between the two instructions creating the hazard?
> [!success]- Solution
> 
> Let $L$ = the instruction is LW
> 
> | n   | B   | B with forwarding |
> | --- | --- | ----------------- |
> | 0   | 3   | L ? 1 : 0         |
> | 1   | 2   | 0                 |
> | 2   | 1   | 0                 |
> | 3+  | 0   | 0                 |
> 

How can we mitigate the bubbles with RAW?
> [!success]- Solution
> * Instruction reordering if the result remains the same
> * Data forwarding eliminates the bubbles
## Busy Bit
Explain the behavior of a busy bit in pipelining
> [!success]- Solution
> * Each [[Register]] in the [[Register File]] gets a bit called the "Busy Bit". 
> * A register's busy bit is set when it is not yet ready to be accessed. 
> * Any instruction that is not yet executing whose registers have a least one busy bit must wait for the currently executing instruction to finish before proceeding down the pipeline.
> * ID/RR sets the busy bit, WB resets it

## Conservative Branch Handling
Explain conservative branch handling, and the outcomes for taking and not taking a branch
> [!success]- Solution
> Upon recognizing a branch instruction (this happens in ID/RR bc decode), stall everything behind it in the pipeline until the outcome of the branch has been calculated.
>
> Scenario: Branch Taken. Branches to It (Inst taken).
> Results in 2 pipeline bubbles.
> 
>
>
> | IF   | ID/RR | EX  | MEM | WB  | Comments                         |
> | ---- | ----- | --- | --- | --- | -------------------------------- |
> | BEQ  |       |     |     |     | Branch not recognized yet        |
> | I2   | BEQ   |     |     |     | Branch recognized; I2 will stall |
> | I2   | NOP   | BEQ |     |     | Branch outcome calculated: TAKEN |
> | It   | NOP   | NOP | BEQ |     | It replaces IF contents          |
> | It+1 | It    | NOP | NOP | BEQ | Continue                         |
> 
> Scenario: Branch Not Taken. 
> Results in only 1 pipeline bubble.
> 
>
>
> | IF  | ID/RR | EX  | MEM | WB  | Comments                             |
> | --- | ----- | --- | --- | --- | ------------------------------------ |
> | BEQ |       |     |     |     | Branch not recognized yet            |
> | I2  | BEQ   |     |     |     | Branch recognized; I2 will stall     |
> | I2  | NOP   | BEQ |     |     | Branch outcome calculated: NOT TAKEN |
> | I3  | I2    | NOP | BEQ |     | Continue                             |
> | I4  | I3    | I2  | NOP | BEQ | Continue                             |
> 

## Branch Prediction Mechanisms
Explain the simplest implementation of branch prediction, and what it achieves.
> [!success]- Solution
Assume branch not taken
Continue in pipeline
Prediction may be wrong, flush the instructions at IF and ID/RR, adjust PC if needed
The term for this is speculative execution
If prediction is correct, then we get pipelining benefit, and it is as if no branch took place
![[Pasted image 20250923194132.png|400]]
![[Pasted image 20250923194511.png|400]]
![[Pasted image 20250923194531.png|400]]

## Interrupts
An interrupt can occur at any time.
Any one of the instructions in the pipeline can cause a discontinuity.
* When do we take the interrupt?
	* We could stop, drain the pipeline, then go to the interrupt state
		* Slow
	* Look for external INT in a specific stage (e.g. EX state)
		* DRAIN preceding stages
		* FLUSH subsequent instructions



# Performance
## Frequency
Explain what static and dynamic frequency are
> [!success]- Solution
> Static frequency refers to the percentage of a program that a particular instruction occurs.
> Dynamic frequency refers to the percentage of a process that a particular instruction occurs.
> Example: The ADD instruction occurs once with a program. It is inside of a loop that executes $X$ times. The total number of instructions of the program is $N_1$. The total number of instructions executing during the duration of the process is $N_2$
> Therefore:
> $$\text{Static Frequency} = \frac{1}{N_{1}}$$
> $$\text{Dynamic Frequency} = \frac{X}{N_{2}}$$
## Execution Time
$$
\text{Execution time} = n \cdot \text{CPI}_{\text{avg}} \cdot \text{clock cycle time}
$$
## Geometric Mean
This is generally the default
The metric removes the bias present in arithmetic mean
## Arithmetic Mean
This metric is biased towards time-consuming jobs
## Harmonic Mean
This metric is biased against time-consuming jobs
## Metrics
$$
\text{speedup}_{\text{A over B}} = \frac{\text{Execution Time on Processor B}}{\text{Execution Time on Processor A}}
$$
$$
\text{speedup}_{\text{improved}} = \frac{\text{Execution Time Before Improvement}}{\text{Execution Time After Improvement}}
$$
$$
\text{improvement in execution time} = \frac{\text{old execution time}-\text{new execution time}}{\text{old execution time}}
$$
$$
\textbf{Amdahl's Law:}\quad\text{Time}_{\text{after}} = \frac{\text{Time}_{\text{affected}}}{\text{Amount of Improvement}} + \text{Time}_{\text{unaffected}}
$$

# Process Scheduling
## Scheduling Metrics
Average Turnaround Time
Average Waiting Time
Average Execution Time
Throughput
CPU Utilization
## Scheduling Algorithms
### FCFS
Do first come first serve. Assume nonpreemptive. 
### Round Robin
![[Round Robin]]

### SRTF
Do the shortest remaining time job first
Always preemptive.
### SJF
Do the shortest job first
Always nonpreemptive.
### Priority
Do the highest priority job first. We assume nonpreemptive. Can be both.
## PCB
Needed by the [[Operating System|OS]] for each [[Process]], so that if a process is suspended by the [[Scheduler]], it can be restored at a later time
```
enum state_type {new, read, running, waiting, halted}

typedef struct control_block_type {
	enum state_type state;
	address PC;
	int reg_file[NUMREGS];
	struct control_block * next_pcb;
	int priority;
	address memory_footprint;
} control_block;
```

## Program vs Process
Program is source, processing is executing source.
## Loader
An [[Operating System|OS]] subroutine responsible for loading user programs from [[Storage|disk]] to [[Memory]]
## Dispatcher
An [[Operating System|OS]] subroutine that populates the [[Processor]] [[Register|registers]] with the state of the [[Process]] selected for running by the [[Scheduler#Short Term Scheduler]]